{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main\n",
      "DATASETS_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets\n",
      "DATA_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11\n",
      "TRAIN_CSV_FILE: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/bounding_boxes/train_labels.csv\n",
      "TRAIN_IMAGES_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/images/train\n",
      "TRAIN_LABELS_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/labels/train\n",
      "TEST_CSV_FILE: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/bounding_boxes/test_labels.csv\n",
      "TEST_IMAGES_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/images/test\n",
      "TEST_LABELS_DIR: /Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/datasets/11/labels/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "HOME_DIR = '/Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main'\n",
    "os.chdir(HOME_DIR)\n",
    "\n",
    "DATASETS_DIR = f'{HOME_DIR}/datasets'\n",
    "DATA_DIR = f'{DATASETS_DIR}/11'\n",
    "\n",
    "TRAIN_CSV_FILE = f'{DATA_DIR}/bounding_boxes/train_labels.csv'\n",
    "TRAIN_IMAGES_DIR = f'{DATA_DIR}/images/train'\n",
    "TRAIN_LABELS_DIR = f'{DATA_DIR}/labels/train'\n",
    "SELECTED_TRAIN_IMAGES_DIR= f'{DATA_DIR}/images/train_selected'\n",
    "SELECTED_TRAIN_LABELS_DIR = f'{DATA_DIR}/labels/train_selected'\n",
    "\n",
    "\n",
    "TEST_CSV_FILE = f'{DATA_DIR}/bounding_boxes/test_labels.csv'\n",
    "TEST_IMAGES_DIR = f'{DATA_DIR}/images/test'\n",
    "TEST_LABELS_DIR = f'{DATA_DIR}/labels/test'\n",
    "SELECTED_TEST_IMAGES_DIR = f'{DATA_DIR}/images/test_selected'\n",
    "SELECTED_TEST_LABELS_DIR = f'{DATA_DIR}/labels/test_selected'\n",
    "\n",
    "OUTPUT_IMAGES_DIR = 'week-06-portfolio/evaluation_images'\n",
    "\n",
    "yaml_file_path = f'{DATA_DIR}/graffiti.yaml'\n",
    "\n",
    "print(f'HOME_DIR: {HOME_DIR}')\n",
    "print(f'DATASETS_DIR: {DATASETS_DIR}')\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'TRAIN_CSV_FILE: {TRAIN_CSV_FILE}')\n",
    "print(f'TRAIN_IMAGES_DIR: {TRAIN_IMAGES_DIR}')\n",
    "print(f'TRAIN_LABELS_DIR: {TRAIN_LABELS_DIR}')\n",
    "print(f'TEST_CSV_FILE: {TEST_CSV_FILE}')\n",
    "print(f'TEST_IMAGES_DIR: {TEST_IMAGES_DIR}')\n",
    "print(f'TEST_LABELS_DIR: {TEST_LABELS_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "!pip install -r requirements.txt --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from torchvision.ops import box_iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if platform.system() == 'Darwin':\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_annotations(csv_file, images_dir, output_dir, class_mapping):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    grouped = df.groupby('filename')\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for filename, group in tqdm(grouped, desc=f'Converting annotations for {csv_file}'):\n",
    "        image_path = os.path.join(images_dir, filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            continue  # Skip if image does not exist\n",
    "\n",
    "        img_width = group.iloc[0]['width']\n",
    "        img_height = group.iloc[0]['height']\n",
    "\n",
    "        annotations = []\n",
    "        for _, row in group.iterrows():\n",
    "            class_id = class_mapping[row['class']]\n",
    "            xmin = row['xmin']\n",
    "            ymin = row['ymin']\n",
    "            xmax = row['xmax']\n",
    "            ymax = row['ymax']\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            x_center = ((xmin + xmax) / 2) / img_width\n",
    "            y_center = ((ymin + ymax) / 2) / img_height\n",
    "            bbox_width = (xmax - xmin) / img_width\n",
    "            bbox_height = (ymax - ymin) / img_height\n",
    "\n",
    "            annotations.append(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\")\n",
    "\n",
    "        # Write annotations to file\n",
    "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "        with open(os.path.join(output_dir, txt_filename), 'w') as f:\n",
    "            for ann in annotations:\n",
    "                f.write(ann + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class mapping\n",
    "class_mapping = {'Graffiti': 0}\n",
    "\n",
    "# Convert training annotations\n",
    "convert_annotations(TRAIN_CSV_FILE, TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR, class_mapping)\n",
    "\n",
    "# Convert test annotations\n",
    "convert_annotations(TEST_CSV_FILE, TEST_IMAGES_DIR, TEST_LABELS_DIR, class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_images(source_dir, dest_dir, num_images, used_images=set()):\n",
    "    images = [f for f in os.listdir(source_dir) if f.endswith('.jpg') and f not in used_images]\n",
    "    selected_images = random.sample(images, min(num_images, len(images)))\n",
    "    used_images.update(selected_images)\n",
    "\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    \n",
    "    for file in os.listdir(dest_dir):\n",
    "        file_path = os.path.join(dest_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    \n",
    "    for img in selected_images:\n",
    "        shutil.copy(os.path.join(source_dir, img), os.path.join(dest_dir, img))\n",
    "    return used_images\n",
    "\n",
    "def copy_annotation_files(image_dir, label_source_dir, label_dest_dir):\n",
    "    if not os.path.exists(label_dest_dir):\n",
    "        os.makedirs(label_dest_dir)\n",
    "        \n",
    "    for file in os.listdir(label_dest_dir):\n",
    "        file_path = os.path.join(label_dest_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    \n",
    "    \n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if img_file.endswith('.jpg'):\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = base_name + '.txt'\n",
    "            src_label_path = os.path.join(label_source_dir, label_file)\n",
    "            dst_label_path = os.path.join(label_dest_dir, label_file)\n",
    "            if os.path.exists(src_label_path):\n",
    "                shutil.copy(src_label_path, dst_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Initialize used images sets\n",
    "used_train_images = set()\n",
    "used_test_images = set()\n",
    "\n",
    "# Select 400 random training images\n",
    "used_train_images = select_random_images(TRAIN_IMAGES_DIR, SELECTED_TRAIN_IMAGES_DIR, 400, used_train_images)\n",
    "\n",
    "# Copy corresponding training annotation files\n",
    "copy_annotation_files(SELECTED_TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR, SELECTED_TRAIN_LABELS_DIR)\n",
    "\n",
    "# Select 40 random test images\n",
    "used_test_images = select_random_images(TEST_IMAGES_DIR, SELECTED_TEST_IMAGES_DIR, 40, used_test_images)\n",
    "\n",
    "# Copy corresponding test annotation files\n",
    "copy_annotation_files(SELECTED_TEST_IMAGES_DIR, TEST_LABELS_DIR, SELECTED_TEST_LABELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yaml_file(file_path, train_images, val_images, nc, class_names):\n",
    "    data = {\n",
    "        'train': train_images,\n",
    "        'val': val_images,\n",
    "        'nc': nc,\n",
    "        'names': class_names\n",
    "    }\n",
    "    with open(file_path, 'w') as f:\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, list):\n",
    "                value_str = str(value).replace(\"'\", \"\")\n",
    "                f.write(f\"{key}: {value_str}\\n\")\n",
    "            else:\n",
    "                f.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "train_images_path = os.path.abspath(SELECTED_TRAIN_IMAGES_DIR)\n",
    "val_images_path = os.path.abspath(SELECTED_TEST_IMAGES_DIR)  # Using test data as validation set\n",
    "\n",
    "nc = 1\n",
    "class_names = ['Graffiti']\n",
    "\n",
    "create_yaml_file(yaml_file_path, train_images_path, val_images_path, nc, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLOv5s model\n",
    "model = YOLO('week-06-portfolio/models/yolov5su.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=yaml_file_path, epochs=1, imgsz=640, batch=16, name='graffiti_detection', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred_boxes, true_boxes):\n",
    "    # Convert boxes to tensors\n",
    "    pred_boxes = torch.tensor(pred_boxes)\n",
    "    true_boxes = torch.tensor(true_boxes)\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = box_iou(pred_boxes, true_boxes)\n",
    "    return iou.diag().numpy()  # Get IoUs for matched boxes\n",
    "\n",
    "def evaluate_model(model, images_dir, labels_dir, output_images_dir=None):\n",
    "    results = []\n",
    "    images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    if output_images_dir and not os.path.exists(output_images_dir):\n",
    "        os.makedirs(output_images_dir)\n",
    "\n",
    "    for img_name in tqdm(images, desc='Evaluating model'):\n",
    "        img_path = os.path.join(images_dir, img_name)\n",
    "        label_path = os.path.join(labels_dir, os.path.splitext(img_name)[0] + '.txt')\n",
    "\n",
    "        # Perform inference\n",
    "        preds = model.predict(img_path, conf=0.25)\n",
    "\n",
    "        # Load image for drawing\n",
    "        img = cv2.imread(img_path)\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        # Get predicted boxes and confidence scores\n",
    "        pred_boxes = []\n",
    "        confidences = []\n",
    "        for pred in preds:\n",
    "            for box in pred.boxes:\n",
    "                x_min = box.xyxy[0][0].item()\n",
    "                y_min = box.xyxy[0][1].item()\n",
    "                x_max = box.xyxy[0][2].item()\n",
    "                y_max = box.xyxy[0][3].item()\n",
    "                conf = box.conf.item()\n",
    "                pred_boxes.append([x_min, y_min, x_max, y_max])\n",
    "                confidences.append(conf)\n",
    "\n",
    "                # Draw predicted bounding box\n",
    "                if output_images_dir:\n",
    "                    label = f\"{model.names[int(box.cls)]}: {conf:.2f}\"\n",
    "                    cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                    cv2.putText(img, label, (int(x_min), int(y_min) - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Get true boxes\n",
    "        true_boxes = []\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                    # Convert back to absolute coordinates\n",
    "                    x_center *= img_width\n",
    "                    y_center *= img_height\n",
    "                    width *= img_width\n",
    "                    height *= img_height\n",
    "                    x_min = x_center - width / 2\n",
    "                    y_min = y_center - height / 2\n",
    "                    x_max = x_center + width / 2\n",
    "                    y_max = y_center + height / 2\n",
    "                    true_boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "                    # Draw true bounding box\n",
    "                    if output_images_dir:\n",
    "                        cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 0, 255), 2)\n",
    "\n",
    "        # Save image with drawn bounding boxes\n",
    "        if output_images_dir:\n",
    "            output_image_path = os.path.join(output_images_dir, img_name)\n",
    "            cv2.imwrite(output_image_path, img)\n",
    "\n",
    "        # Compute IoU\n",
    "        if pred_boxes and true_boxes:\n",
    "            ious = compute_iou(pred_boxes, true_boxes)\n",
    "            max_iou = max(ious)\n",
    "            max_conf = confidences[ious.argmax()]\n",
    "        else:\n",
    "            max_iou = 0.0\n",
    "            max_conf = 0.0 if not confidences else max(confidences)\n",
    "\n",
    "        results.append({\n",
    "            'image_name': img_name,\n",
    "            'confidence_value': max_conf,\n",
    "            'IoU_value': max_iou\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m(model, SELECTED_TEST_IMAGES_DIR, SELECTED_TEST_LABELS_DIR, OUTPUT_IMAGES_DIR)\n\u001b[1;32m      3\u001b[0m df_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweek-06-portfolio/evaluation_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "df_results = evaluate_model(model, SELECTED_TEST_IMAGES_DIR, SELECTED_TEST_LABELS_DIR, OUTPUT_IMAGES_DIR)\n",
    "df_results.to_csv('week-06-portfolio/evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Train Base on the Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables for iterative training\n",
    "iou_threshold = 0.9\n",
    "satisfied = False\n",
    "iteration = 1\n",
    "\n",
    "while not satisfied:\n",
    "    print(f\"\\nStarting iteration {iteration}\")\n",
    "\n",
    "    # Select new training images\n",
    "    training_images = random.sample(os.listdir(TRAIN_IMAGES_DIR), 400)\n",
    "\n",
    "    # Update training data directories\n",
    "    selected_train_images_dir = f'week-06-portfolio/images/train_selected_iter_{iteration}'\n",
    "    selected_train_labels_dir = f'week-06-portfolio/labels/train_selected_iter_{iteration}'\n",
    "    if not os.path.exists(selected_train_images_dir):\n",
    "        os.makedirs(selected_train_images_dir)\n",
    "    if not os.path.exists(selected_train_labels_dir):\n",
    "        os.makedirs(selected_train_labels_dir)\n",
    "\n",
    "    # Copy selected images and annotations\n",
    "    for img in training_images:\n",
    "        shutil.copy(os.path.join(TRAIN_IMAGES_DIR, img), os.path.join(selected_train_images_dir, img))\n",
    "        label_file = os.path.splitext(img)[0] + '.txt'\n",
    "        src_label_path = os.path.join(TRAIN_LABELS_DIR, label_file)\n",
    "        dst_label_path = os.path.join(selected_train_labels_dir, label_file)\n",
    "        if os.path.exists(src_label_path):\n",
    "            shutil.copy(src_label_path, dst_label_path)\n",
    "\n",
    "    # Update YAML file\n",
    "    train_images_path = os.path.abspath(selected_train_images_dir)\n",
    "    val_images_path = os.path.abspath(SELECTED_TEST_IMAGES_DIR)\n",
    "\n",
    "    # Update the YAML file path for this iteration\n",
    "    yaml_dir = 'week-06-portfolio/yaml'\n",
    "    if not os.path.exists(yaml_dir):\n",
    "        os.makedirs(yaml_dir)\n",
    "        \n",
    "    yaml_file_path_iter = f'week-06-portfolio/yaml/graffiti_iter_{iteration}.yaml'\n",
    "    create_yaml_file(yaml_file_path_iter, train_images_path, val_images_path, nc, class_names)\n",
    "\n",
    "    # Load the model from previous iteration\n",
    "    if iteration == 1:\n",
    "        model = YOLO('week-06-portfolio/models/yolov5su.pt')  # Start with pre-trained YOLOv5su model\n",
    "    else:\n",
    "        previous_model_path = f'week-06-portfolio/runs/train/graffiti_detection_iter_{iteration - 1}/weights/best.pt'\n",
    "        model = YOLO(previous_model_path)\n",
    "\n",
    "    # Train the model with 5 epochs\n",
    "    model.train(\n",
    "        data=yaml_file_path_iter,\n",
    "        epochs=5,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        project='week-06-portfolio/runs/train',\n",
    "        name=f'graffiti_detection_iter_{iteration}',\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    output_images_dir_iter = f'week-06-portfolio/evaluation_images_iter_{iteration}'\n",
    "    if not os.path.exists(output_images_dir_iter):\n",
    "        os.makedirs(output_images_dir_iter)\n",
    "\n",
    "    df_results = evaluate_model(model, SELECTED_TEST_IMAGES_DIR, SELECTED_TEST_LABELS_DIR, output_images_dir_iter)\n",
    "    df_results.to_csv(f'week-06-portfolio/evaluation_results_iter_{iteration}.csv', index=False)\n",
    "\n",
    "    # Check IoU threshold\n",
    "    over_threshold = df_results[df_results['IoU_value'] > iou_threshold]\n",
    "    if len(over_threshold) / len(df_results) >= 0.8:\n",
    "        print(f\"IoU threshold met in iteration {iteration}\")\n",
    "        model.save(f'week-06-portfolio/models/yolov5s_graffiti_iter_{iteration}.pt')\n",
    "        satisfied = True\n",
    "    else:\n",
    "        print(f\"IoU threshold not met in iteration {iteration}\")\n",
    "\n",
    "    # Prepare for next iteration\n",
    "    iteration += 1\n",
    "\n",
    "\n",
    "if not satisfied:\n",
    "    print(\"IoU threshold not met after all iterations.\")\n",
    "else:\n",
    "    print(\"Training completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_items_and_folders(source_dir, target_dir, exclude_dirs):\n",
    "\n",
    "    # Ensure the source directory exists\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Error: Source directory does not exist: {source_dir}\")\n",
    "        return\n",
    "\n",
    "    # Create the target directory if it does not exist\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "        print(f\"Created target directory: {target_dir}\")\n",
    "    else:\n",
    "        print(f\"Target directory already exists: {target_dir}\")\n",
    "\n",
    "    # Iterate over all items in the source directory\n",
    "    for item in os.listdir(source_dir):\n",
    "        item_path = os.path.join(source_dir, item)\n",
    "\n",
    "        # Skip the target directory itself to prevent recursive moving\n",
    "        if os.path.abspath(item_path) == os.path.abspath(target_dir):\n",
    "            print(f\"Skipped target directory itself: '{item}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the item is a directory\n",
    "        if os.path.isdir(item_path):\n",
    "            if item in exclude_dirs:\n",
    "                print(f\"Excluded directory: '{item}'.\")\n",
    "                continue  # Skip excluded directories\n",
    "\n",
    "            # Define the destination path\n",
    "            dest_path = os.path.join(target_dir, item)\n",
    "\n",
    "            # Check if destination already exists\n",
    "            if os.path.exists(dest_path):\n",
    "                print(f\"Skipped: Destination already exists for folder '{item}'.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Move the directory\n",
    "                shutil.move(item_path, dest_path)\n",
    "                print(f\"Moved folder '{item}' to '{target_dir}'.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving folder '{item}': {e}\")\n",
    "\n",
    "        elif os.path.isfile(item_path):\n",
    "            # If the item is a file, move it to the target directory\n",
    "            dest_path = os.path.join(target_dir, item)\n",
    "\n",
    "            # Check if destination file already exists\n",
    "            if os.path.exists(dest_path):\n",
    "                print(f\"Skipped: Destination already exists for file '{item}'.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                shutil.move(item_path, dest_path)\n",
    "                print(f\"Moved file '{item}' to '{target_dir}'.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving file '{item}': {e}\")\n",
    "\n",
    "        else:\n",
    "            # For any other types of items (e.g., symbolic links), skip them\n",
    "            print(f\"Skipped non-directory, non-file item: '{item}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'move_items_and_folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m TARGET_TRAIN_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(WEEK_6_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m EXCLUDE_DIRS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrequirements\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmove_items_and_folders\u001b[49m(WEEK_6_DIR, TARGET_TRAIN_DIR, EXCLUDE_DIRS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'move_items_and_folders' is not defined"
     ]
    }
   ],
   "source": [
    "WEEK_6_DIR = '/Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/week-06-portfolio'\n",
    "TARGET_TRAIN_DIR = os.path.join(WEEK_6_DIR, 'train')\n",
    "EXCLUDE_DIRS = ['code', 'docs', 'requirements', 'models']\n",
    "move_items_and_folders(WEEK_6_DIR, TARGET_TRAIN_DIR, EXCLUDE_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run on URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/Users/ag47/Desktop/COS40007-Artificial-Intelligence-for-Engineering-main/week-06-portfolio/train/runs/train/graffiti_detection_iter_30/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Run\n",
    "source = 'https://videos.pexels.com/video-files/4543511/4543511-hd_1080_1920_25fps.mp4'\n",
    "results = model.track(source, save=True, project=f'{HOME_DIR}/week-06-portfolio/results', tracker=\"bytetrack.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    pattern = r'-([\\d]+)/$'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_video_name(video_url):\n",
    "    pattern = r'/([\\d]+-[\\w]+_[\\d]+_[\\d]+_[\\d]+fps\\.mp4)$'\n",
    "    match = re.search(pattern, video_url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEXELS API DOC\n",
    "# https://www.pexels.com/api/documentation/\n",
    "\n",
    "# TUTOR MAY WANT TO REPLACE WITH YOUR OWN API KEY!\n",
    "PEXELS_API = '3W6w2EgXgVBeG8j469C9YuOMLvi6xMPeFgbyd8w72vm0GjnCKuqxJzUZ'\n",
    "\n",
    "# Function to get the HD video link\n",
    "def get_hd_video_link(video_id):\n",
    "    url = f\"https://api.pexels.com/videos/videos/{video_id}\"\n",
    "    command = f'curl -H \"Authorization: {PEXELS_API}\" {url}'\n",
    "    response = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(response.stdout)\n",
    "        # Look for the hd link in video_files\n",
    "        for video_file in data['video_files']:\n",
    "            if video_file['quality'] == 'hd':\n",
    "                return video_file['link']\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to retrieve video data for ID: {video_id}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://videos.pexels.com/video-files/4543511/4543511-hd_720_1280_50fps.mp4\n",
      "4543511-hd_720_1280_50fps.mp4\n",
      "https://videos.pexels.com/video-files/854181/854181-hd_1920_1080_25fps.mp4\n",
      "854181-hd_1920_1080_25fps.mp4\n",
      "https://videos.pexels.com/video-files/3413463/3413463-hd_1920_1080_30fps.mp4\n",
      "3413463-hd_1920_1080_30fps.mp4\n",
      "https://videos.pexels.com/video-files/9724130/9724130-hd_1440_1080_30fps.mp4\n",
      "9724130-hd_1440_1080_30fps.mp4\n"
     ]
    }
   ],
   "source": [
    "# List of URLs\n",
    "urls = [\n",
    "    \"https://www.pexels.com/video/a-door-with-graffiti-on-it-is-shown-4543511/\",\n",
    "    \"https://www.pexels.com/video/busy-street-footage-854181/\",\n",
    "    \"https://www.pexels.com/video/graffiti-painted-on-the-train-station-wall-3413463/\",\n",
    "    \"https://www.pexels.com/video/a-man-writing-on-a-wall-with-a-marker-9724130/\"\n",
    "]\n",
    "\n",
    "# Extract and print HD video links for each URL\n",
    "for url in urls:\n",
    "    video_id = extract_video_id(url)\n",
    "    if video_id:\n",
    "        hd_link = get_hd_video_link(video_id)\n",
    "        if hd_link:\n",
    "            print(f\"{hd_link}\")\n",
    "            print(f'{get_video_name(hd_link)}')\n",
    "    else:\n",
    "        print(f\"Could not extract video ID from URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predcit and track the video with the model\n",
    "for url in urls:\n",
    "    video_id = extract_video_id(url)\n",
    "    if video_id:\n",
    "        hd_link = get_hd_video_link(video_id)\n",
    "        if hd_link:\n",
    "            print(f\"Proceessing: {hd_link}\")\n",
    "            video_name = get_video_name(hd_link)\n",
    "            model.track(hd_link, save=True, project=f'{HOME_DIR}/week-06-portfolio/results', conf=0.5, iou=0.9,  tracker=\"bytetrack.yaml\", device=device)\n",
    "            if os.path.exists(f'{HOME_DIR}/{video_name}'):\n",
    "                os.remove(f'{HOME_DIR}/{video_name}')\n",
    "    else:\n",
    "        print(f\"Could not extract video ID from URL: {url}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
